{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORLD CUP FINALIST PREDICTION SYSTEM\n",
      "==================================================\n",
      "Created finalist target:\n",
      "   Finalist candidates: ['ar Argentina', 'be Belgium', 'co Colombia', 'de Germany', 'fr France', 'nl Netherlands']\n",
      "\n",
      " PREDICTING WORLD CUP FINALISTS\n",
      "============================================================\n",
      "\n",
      "  MODEL EVALUATION\n",
      "============================================================\n",
      "\n",
      " Performance Comparison:\n",
      "              Model  Accuracy  AUC-ROC  Precision  Recall  F1-Score\n",
      "      Random Forest     1.000      1.0      1.000     1.0       1.0\n",
      "Logistic Regression     0.833      1.0      0.333     1.0       0.5\n",
      "            XGBoost     0.917      1.0      0.000     0.0       0.0\n",
      "\n",
      " BEST MODEL: Random Forest\n",
      " F1-Score: 1.000, AUC-ROC: 1.000\n",
      " Using best model: Random Forest\n",
      "\n",
      " TOP PREDICTED FINALISTS:\n",
      "--------------------------------------------------\n",
      "   co Colombia          | Prob: 0.970 | ACTUAL FINALIST\n",
      "   de Germany           | Prob: 0.970 | ACTUAL FINALIST\n",
      "   nl Netherlands       | Prob: 0.950 | ACTUAL FINALIST\n",
      "   be Belgium           | Prob: 0.920 | ACTUAL FINALIST\n",
      "   fr France            | Prob: 0.860 | ACTUAL FINALIST\n",
      "   ar Argentina         | Prob: 0.800 | ACTUAL FINALIST\n",
      "   br Brazil            | Prob: 0.280 |  PREDICTED\n",
      "   es Spain             | Prob: 0.060 |  PREDICTED\n",
      "   it Italy             | Prob: 0.030 |  PREDICTED\n",
      "   uy Uruguay           | Prob: 0.020 |  PREDICTED\n",
      "\n",
      " FINAL PREDICTION - WORLD CUP FINALISTS:\n",
      " 1. co Colombia\n",
      " Probability: 0.970\n",
      " Win Rate: 0.667\n",
      " WC Experience: 2 tournaments\n",
      "\n",
      " 2. de Germany\n",
      " Probability: 0.970\n",
      " Win Rate: 0.667\n",
      " WC Experience: 5 tournaments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,  confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class WorldCupFinalistPredictor:\n",
    "    def __init__(self, data_file):\n",
    "        self.df = pd.read_excel(data_file)\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    def create_finalist_target(self):\n",
    "    \n",
    "        conditions = [\n",
    "                # Elite performance criteria\n",
    "                (self.df['win_rate'] > 0.6) & (self.df['goal_ratio'] > 1.5) & (self.df['world_cup_experience'] >= 3),\n",
    "            \n",
    "                # Historical powerhouses with consistent performance\n",
    "                (self.df['world_cup_experience'] >= 4) & (self.df['win_rate'] > 0.6) & (self.df['points_per_game'] > 1.65),\n",
    "            \n",
    "                # Very dominant teams (high goal ratio)\n",
    "                (self.df['goal_ratio'] > 2.0) & (self.df['win_rate'] > 0.55)\n",
    "            ]\n",
    "        \n",
    "        choices = [1, 1, 1]  # Mark as potential finalist\n",
    "        \n",
    "        self.df['is_finalist'] = np.select(conditions, choices, default=0)\n",
    "        \n",
    "        print(f\"Created finalist target:\")\n",
    "        \n",
    "        # Show \"finalists\"\n",
    "        finalists = self.df[self.df['is_finalist'] == 1]['Squad'].tolist()\n",
    "        print(f\"   Finalist candidates: {finalists}\")\n",
    "    \n",
    "        return self.df\n",
    "\n",
    "    def feature(self):\n",
    "    \n",
    "      # Use ALL available features from your dataset\n",
    "      feature_columns = [\n",
    "        'win_rate', 'goal_ratio', 'world_cup_experience', 'Appearances',\n",
    "        'points_per_game', 'goal_diff_per_game', 'GF_per_game', 'GA_per_game',\n",
    "        'xG_per_game', 'xGA_per_game', 'xGD_per_game', 'W_per_game', 'D_per_game', 'L_per_game',\n",
    "        'attack_power', 'defense_strength', 'team_consistency', 'performance_efficiency'\n",
    "      ]\n",
    "    \n",
    "      # Handle missing values properly\n",
    "      for col in feature_columns:\n",
    "          if col in self.df.columns:\n",
    "              self.df[col] = self.df[col].fillna(self.df[col].median())\n",
    "      \n",
    "      return [col for col in feature_columns if col in self.df.columns]\n",
    "\n",
    "    def prepare_data(self):\n",
    "    \n",
    "      # Get enhanced features\n",
    "      feature_columns = self.feature()\n",
    "    \n",
    "      # Create actual target\n",
    "      if 'is_finalist' not in self.df.columns:\n",
    "          self.create_finalist_target()\n",
    "    \n",
    "      # Remove missing values\n",
    "      clean_df = self.df[feature_columns + ['is_finalist']].dropna()\n",
    "    \n",
    "      self.X = clean_df[feature_columns]\n",
    "      self.y = clean_df['is_finalist']\n",
    "    \n",
    "      # Use Stratified Split to maintain class distribution\n",
    "      self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "          self.X, self.y, test_size=0.2, random_state=42, stratify=self.y\n",
    "      )\n",
    "    \n",
    "      # Scale features\n",
    "      self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "      self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "    \n",
    "      return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "\n",
    "    def build_models(self):\n",
    "      \n",
    "      \n",
    "      models = {\n",
    "          'Logistic Regression': {\n",
    "              'model': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "              'params': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga']}\n",
    "          },\n",
    "          'Random Forest': {\n",
    "              'model': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "              'params': {'n_estimators': [100, 200], 'max_depth': [10, 15, None]}\n",
    "         },\n",
    "         'XGBoost': {\n",
    "             'model': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "             'params': {'n_estimators': [100, 200], 'max_depth': [3, 6, 9], 'learning_rate': [0.01, 0.1]}\n",
    "         }\n",
    "      }\n",
    "    \n",
    "      for name, config in models.items():\n",
    "        \n",
    "          try:\n",
    "              # Use GridSearch for hyperparameter tuning\n",
    "              grid_search = GridSearchCV(\n",
    "                  config['model'], config['params'], \n",
    "                  cv=5, scoring='roc_auc', n_jobs=-1\n",
    "              )\n",
    "            \n",
    "              # Choose data based on model type\n",
    "              if name == 'Logistic Regression':\n",
    "                  grid_search.fit(self.X_train_scaled, self.y_train)\n",
    "                  best_model = grid_search.best_estimator_\n",
    "                  y_pred_proba = best_model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "                  y_pred = best_model.predict(self.X_test_scaled)\n",
    "              else:\n",
    "                  grid_search.fit(self.X_train, self.y_train)\n",
    "                  best_model = grid_search.best_estimator_\n",
    "                  y_pred_proba = best_model.predict_proba(self.X_test)[:, 1]\n",
    "                  y_pred = best_model.predict(self.X_test)\n",
    "            \n",
    "              # Calculate comprehensive metrics\n",
    "              accuracy = accuracy_score(self.y_test, y_pred)\n",
    "              auc_roc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "            \n",
    "              # Store results\n",
    "              self.models[name] = best_model\n",
    "              self.results[name] = {\n",
    "                  'accuracy': accuracy,\n",
    "                  'auc_roc': auc_roc,\n",
    "                  'predictions': y_pred,\n",
    "                  'probabilities': y_pred_proba,\n",
    "                  'model': best_model,\n",
    "                  'best_params': grid_search.best_params_\n",
    "              }\n",
    "            \n",
    "            \n",
    "          except Exception as e:\n",
    "              print(f\"Error training {name}: {e}\")\n",
    "    \n",
    "      return self.models\n",
    "\n",
    "    def evaluate_models(self):\n",
    "      \"\"\" model evaluation with detailed metrics\"\"\"\n",
    "      print(\"\\n  MODEL EVALUATION\")\n",
    "      print(\"=\" * 60)\n",
    "    \n",
    "      comparison = []\n",
    "    \n",
    "      for name, metrics in self.results.items():\n",
    "          y_pred = metrics['predictions']\n",
    "          y_true = self.y_test\n",
    "        \n",
    "          # Calculate comprehensive metrics\n",
    "          cm = confusion_matrix(y_true, y_pred)\n",
    "          tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "          precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "          recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "          f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "          # Cross-validation scores\n",
    "          if name == 'Logistic Regression':\n",
    "              cv_scores = cross_val_score(metrics['model'], self.X_train_scaled, self.y_train, cv=5, scoring='roc_auc')\n",
    "          else:\n",
    "              cv_scores = cross_val_score(metrics['model'], self.X_train, self.y_train, cv=5, scoring='roc_auc')\n",
    "        \n",
    "          comparison.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': metrics['accuracy'],\n",
    "            'AUC-ROC': metrics['auc_roc'],\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'CV_AUC_Mean': cv_scores.mean()\n",
    "          })\n",
    "    \n",
    "      results_df = pd.DataFrame(comparison)\n",
    "      results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "      print(\"\\n Performance Comparison:\")\n",
    "      print(results_df.round(3).to_string(index=False))\n",
    "    \n",
    "      # Show best model\n",
    "      best_model_row = results_df.iloc[0]\n",
    "      print(f\"\\n BEST MODEL: {best_model_row['Model']}\")\n",
    "      print(f\" F1-Score: {best_model_row['F1-Score']:.3f}, AUC-ROC: {best_model_row['AUC-ROC']:.3f}\")\n",
    "    \n",
    "      return results_df\n",
    "\n",
    "    def predict_finalists(self):\n",
    "      \"\"\"Finalist prediction \"\"\"\n",
    "      print(\"\\n PREDICTING WORLD CUP FINALISTS\")\n",
    "      print(\"_\" * 60)\n",
    "    \n",
    "      # Use the best model based on F1-score\n",
    "      best_model_name = self.evaluate_models().iloc[0]['Model']\n",
    "      best_model = self.models[best_model_name]\n",
    "    \n",
    "      print(f\" Using best model: {best_model_name}\")\n",
    "    \n",
    "      # Prepare all data for prediction\n",
    "      feature_columns = self.X.columns.tolist()\n",
    "      X_all = self.df[feature_columns].dropna()\n",
    "      team_indices = X_all.index\n",
    "      teams = self.df.loc[team_indices, 'Squad']\n",
    "    \n",
    "      # Get predictions for all teams\n",
    "      if best_model_name == 'Logistic Regression':\n",
    "          X_all_scaled = self.scaler.transform(X_all)\n",
    "          probabilities = best_model.predict_proba(X_all_scaled)[:, 1]\n",
    "      else:\n",
    "          probabilities = best_model.predict_proba(X_all)[:, 1]\n",
    "    \n",
    "      # Create comprehensive results\n",
    "      results = pd.DataFrame({\n",
    "        'Team': teams,\n",
    "        'Finalist_Probability': probabilities,\n",
    "        'Actual_Finalist': self.df.loc[team_indices, 'is_finalist'],\n",
    "        'Win_Rate': self.df.loc[team_indices, 'win_rate'],\n",
    "        'World_Cup_Experience': self.df.loc[team_indices, 'world_cup_experience']\n",
    "      })\n",
    "    \n",
    "      # Sort by probability\n",
    "      results = results.sort_values('Finalist_Probability', ascending=False)\n",
    "    \n",
    "      # Show top predictions\n",
    "      print(\"\\n TOP PREDICTED FINALISTS:\")\n",
    "      print(\"-\" * 50)\n",
    "      top_teams = results.head(10)\n",
    "    \n",
    "      for idx, row in top_teams.iterrows():\n",
    "          status = \"ACTUAL FINALIST\" if row['Actual_Finalist'] == 1 else \" PREDICTED\"\n",
    "          print(f\"   {row['Team']:20} | Prob: {row['Finalist_Probability']:.3f} | {status}\")\n",
    "    \n",
    "      # Select final two finalists\n",
    "      finalists = results.head(2)\n",
    "    \n",
    "      print(f\"\\n FINAL PREDICTION - WORLD CUP FINALISTS:\")\n",
    "\n",
    "      for i, (idx, team) in enumerate(finalists.iterrows(), 1):\n",
    "          print(f\" {i}. {team['Team']}\")\n",
    "          print(f\" Probability: {team['Finalist_Probability']:.3f}\")\n",
    "          print(f\" Win Rate: {team['Win_Rate']:.3f}\")\n",
    "          print(f\" WC Experience: {team['World_Cup_Experience']} tournaments\")\n",
    "          print()\n",
    "    \n",
    "      return results\n",
    "\n",
    "      \n",
    "def main():\n",
    "    \n",
    "    print(\"WORLD CUP FINALIST PREDICTION SYSTEM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    predictor = WorldCupFinalistPredictor('aggregated_team_stats.xlsx')\n",
    "    \n",
    "    predictor.prepare_data()\n",
    "    predictor.build_models()\n",
    "    predictions = predictor.predict_finalists()\n",
    "    \n",
    "    return predictor, predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor, predictions = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bf0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
