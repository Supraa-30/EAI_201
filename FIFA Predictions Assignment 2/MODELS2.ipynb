{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf779b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ ACTUAL Finalist Distribution:\n",
      "   Finalists: 28\n",
      "   Non-Finalists: 31\n",
      "   Actual Finalist Teams: ['ar Argentina', 'au Australia', 'ch Switzerland', 'cl Chile', 'co Colombia', 'de Germany', 'dk Denmark', 'dz Algeria', 'ec Ecuador', 'eng England', 'es Spain', 'fr France', 'gh Ghana', 'gr Greece', 'hr Croatia', 'it Italy', 'jp Japan', 'kr Korea Republic', 'mx Mexico', 'ng Nigeria', 'nl Netherlands', 'pl Poland', 'pt Portugal', 'se Sweden', 'sk Slovakia', 'sn Senegal', 'us United States', 'uy Uruguay']\n",
      "Class Distribution: (array([0, 1]), array([31, 28]))\n",
      "\n",
      " PREDICTION MODELS\n",
      "==================================================\n",
      "\n",
      " Logistic Regression...\n",
      " Accuracy: 0.750\n",
      " AUC-ROC: 0.806\n",
      "\n",
      " Random Forest...\n",
      " Accuracy: 0.833\n",
      " AUC-ROC: 1.000\n",
      "\n",
      " XGBoost...\n",
      " Accuracy: 0.667\n",
      " AUC-ROC: 0.806\n",
      "\n",
      " Gradient Boosting...\n",
      " Accuracy: 0.750\n",
      " AUC-ROC: 0.806\n",
      "\n",
      " MODEL EVALUATION\n",
      "==================================================\n",
      "              Model  Accuracy  AUC-ROC  Precision  Recall  F1-Score\n",
      "      Random Forest     0.833    1.000      0.750   1.000     0.857\n",
      "Logistic Regression     0.750    0.806      0.714   0.833     0.769\n",
      "  Gradient Boosting     0.750    0.806      0.714   0.833     0.769\n",
      "            XGBoost     0.667    0.806      0.625   0.833     0.714\n",
      "\n",
      " PREDICTING FINALISTS\n",
      "==================================================\n",
      "Using best model: Random Forest\n",
      "\n",
      " PREDICTED FINALIST PAIRS:\n",
      " ch Switzerland (100.000%)\n",
      " uy Uruguay (99.000%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class WorldCupFinalistPredictor:\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\"Initialize the finalist predictor\"\"\"\n",
    "        self.df = pd.read_excel(data_file)\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    def create_finalist_target(self):\n",
    "      \"\"\"Use ACTUAL historical finalist data from Rk column\"\"\"\n",
    "      def is_finalist(rk_value):\n",
    "          if isinstance(rk_value, str):\n",
    "              # Teams that finished 1st or 2nd in any World Cup\n",
    "              if '1' in rk_value or '2' in rk_value:\n",
    "                  return 1\n",
    "          return 0\n",
    "    \n",
    "      self.df['is_finalist'] = self.df['Rk'].apply(is_finalist)\n",
    "    \n",
    "      print(f\"ðŸŽ¯ ACTUAL Finalist Distribution:\")\n",
    "      print(f\"   Finalists: {self.df['is_finalist'].sum()}\")\n",
    "      print(f\"   Non-Finalists: {len(self.df) - self.df['is_finalist'].sum()}\")\n",
    "    \n",
    "      actual_finalists = self.df[self.df['is_finalist'] == 1]['Squad'].tolist()\n",
    "      print(f\"   Actual Finalist Teams: {actual_finalists}\")\n",
    "    \n",
    "      return self.df\n",
    "\n",
    "    def feature(self):\n",
    "    \n",
    "      # Use ALL available features from your dataset\n",
    "      feature_columns = [\n",
    "        'win_rate', 'goal_ratio', 'world_cup_experience', 'Appearances',\n",
    "        'points_per_game', 'goal_diff_per_game', 'GF_per_game', 'GA_per_game',\n",
    "        'xG_per_game', 'xGA_per_game', 'xGD_per_game', 'W_per_game', 'D_per_game', 'L_per_game',\n",
    "        'attack_power', 'defense_strength', 'team_consistency', 'performance_efficiency'\n",
    "      ]\n",
    "    \n",
    "      # Handle missing values properly\n",
    "      for col in feature_columns:\n",
    "          if col in self.df.columns:\n",
    "              self.df[col] = self.df[col].fillna(self.df[col].median())\n",
    "      \n",
    "      return [col for col in feature_columns if col in self.df.columns]\n",
    "\n",
    "    def prepare_data(self):\n",
    "      \"\"\"Prepare data with proper class imbalance handling\"\"\"\n",
    "    \n",
    "      # Get enhanced features\n",
    "      feature_columns = self.feature()\n",
    "    \n",
    "      # Create actual target\n",
    "      if 'is_finalist' not in self.df.columns:\n",
    "          self.create_finalist_target()\n",
    "    \n",
    "      # Remove missing values\n",
    "      clean_df = self.df[feature_columns + ['is_finalist']].dropna()\n",
    "    \n",
    "      self.X = clean_df[feature_columns]\n",
    "      self.y = clean_df['is_finalist']\n",
    "    \n",
    "      print(f\"Class Distribution: {np.unique(self.y, return_counts=True)}\")\n",
    "    \n",
    "      # Use Stratified Split to maintain class distribution\n",
    "      self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "          self.X, self.y, test_size=0.2, random_state=42, stratify=self.y\n",
    "      )\n",
    "    \n",
    "      # Scale features\n",
    "      self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "      self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "    \n",
    "      return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "    def build_models(self):\n",
    "        \"\"\"Build and train multiple models\"\"\"\n",
    "        print(\"\\n PREDICTION MODELS\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        models = {\n",
    "            'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "            'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n",
    "            'XGBoost': XGBClassifier(\n",
    "                scale_pos_weight=len(self.y_train[self.y_train==0])/len(self.y_train[self.y_train==1]), random_state=42,\n",
    "                eval_metric='logloss'),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "        }\n",
    "\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n {name}...\")\n",
    "\n",
    "            try:\n",
    "                # Use scaled data for Logistic Regression\n",
    "                if name == 'Logistic Regression':\n",
    "                    model.fit(self.X_train_scaled, self.y_train)\n",
    "                    y_pred = model.predict(self.X_test_scaled)\n",
    "                    y_pred_proba = model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "                else:\n",
    "                    model.fit(self.X_train, self.y_train)\n",
    "                    y_pred = model.predict(self.X_test)\n",
    "                    y_pred_proba = model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(self.y_test, y_pred)\n",
    "                auc_roc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "\n",
    "                self.models[name] = model\n",
    "                self.results[name] = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'auc_roc': auc_roc,\n",
    "                    'predictions': y_pred,\n",
    "                    'probabilities': y_pred_proba,\n",
    "                    'model': model\n",
    "                }\n",
    "\n",
    "                print(f\" Accuracy: {accuracy:.3f}\")\n",
    "                print(f\" AUC-ROC: {auc_roc:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {e}\")\n",
    "\n",
    "        return self.models\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate all models\"\"\"\n",
    "        print(\"\\n MODEL EVALUATION\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        comparison = []\n",
    "\n",
    "        for name, metrics in self.results.items():\n",
    "            y_pred = metrics['predictions']\n",
    "            y_true = self.y_test\n",
    "\n",
    "            # Calculate other metrics\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            comparison.append({\n",
    "                'Model': name,\n",
    "                'Accuracy': metrics['accuracy'],\n",
    "                'AUC-ROC': metrics['auc_roc'],\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1-Score': f1\n",
    "            })\n",
    "\n",
    "        results_df = pd.DataFrame(comparison)\n",
    "        results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "        print(results_df.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def predict_finalists(self):\n",
    "        \"\"\"Predict finalists using all data\"\"\"\n",
    "        print(\"\\n PREDICTING FINALISTS\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Use the best model based on F1-score\n",
    "        best_model_name = max(self.results.items(), key=lambda x: x[1]['f1'])[0] if 'f1' in self.results[list(self.results.keys())[0]] else \\\n",
    "                         max(self.results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "        best_model = self.models[best_model_name]\n",
    "\n",
    "        print(f\"Using best model: {best_model_name}\")\n",
    "\n",
    "\n",
    "        # Prepare all data for prediction\n",
    "        feature_columns = self.X.columns.tolist()\n",
    "        X_all = self.df[feature_columns].dropna()\n",
    "\n",
    "        # Get corresponding team names\n",
    "        team_indices = X_all.index\n",
    "        teams = self.df.loc[team_indices, 'Squad']\n",
    "\n",
    "        # Scale if using scaled model\n",
    "        if best_model_name == 'Logistic Regression':\n",
    "            X_all_scaled = self.scaler.transform(X_all)\n",
    "            probabilities = best_model.predict_proba(X_all_scaled)[:, 1]\n",
    "        else:\n",
    "            probabilities = best_model.predict_proba(X_all)[:, 1]\n",
    "\n",
    "        # Create results dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Team': teams,\n",
    "            'Finalist_Probability': probabilities\n",
    "        })\n",
    "\n",
    "        # Sort by probability\n",
    "        results = results.sort_values('Finalist_Probability', ascending=False)\n",
    "\n",
    "\n",
    "        # Show predicted finalist pairs\n",
    "        print(\"\\n PREDICTED FINALIST PAIRS:\")\n",
    "        top_2 = results.head(2)\n",
    "        for idx, row in top_2.iterrows():\n",
    "            print(f\" {row['Team']} ({row['Finalist_Probability']:.3%})\")\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"Main function to run the prediction\"\"\"\n",
    "\n",
    "    # Initialize predictor\n",
    "    predictor = WorldCupFinalistPredictor('aggregated_team_stats.xlsx')\n",
    "\n",
    "    # Prepare data and build models\n",
    "    predictor.prepare_data()\n",
    "    predictor.build_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = predictor.evaluate_models()\n",
    "\n",
    "    # Predict finalists\n",
    "    final_predictions = predictor.predict_finalists()\n",
    "\n",
    "    return predictor, final_predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor, predictions = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e44fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
